{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-08 00:36:14.491226: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-08 00:36:14.600737: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-01-08 00:36:14.604715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-08 00:36:14.604730: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-01-08 00:36:14.633495: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-08 00:36:15.126799: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-08 00:36:15.126855: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-08 00:36:15.126861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as kr\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "import keras_tuner\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 9024)\n",
      "(180, 9024)\n",
      "9024\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/vmh/vmhdocs/Research/Inria/Anl/MetaGenAutoencoder/Data/KO_metaG.norm.txt\",sep=\"\\t\")\n",
    "df = df.iloc[:,2-len(df.columns):]\n",
    "print(df.shape)\n",
    "df.head(5)\n",
    "\n",
    "train_data = np.array(df)\n",
    "print(train_data.shape)\n",
    "inputlen = len(df.columns)\n",
    "print(inputlen)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model and hyperparameters to be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f66aaf57580>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def autoencoder(units, lr):\n",
    "    inputlen = 9024\n",
    "    encoding_dim = 3\n",
    "    # This is my model\n",
    "    model = kr.Sequential()\n",
    "    model.add(kr.Input(shape=(inputlen,)))\n",
    "    model.add(layers.Dense(units=units*2, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(units=units, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(encoding_dim, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(units=units, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(units=units*2, activation='relu'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dense(inputlen, activation='linear'))\n",
    "    \n",
    "   # This model maps an input to its reconstruction\n",
    "    autoencoder = kr.Model(model.input, model.output)\n",
    "    opt = kr.optimizers.Adam(learning_rate=lr)\n",
    "    autoencoder.compile(optimizer=opt, loss='mse',metrics=[\"mean_squared_error\"])\n",
    "    return autoencoder\n",
    "\n",
    "def build_model(hp):\n",
    "    units = hp.Int(\"units\", min_value=100, max_value=1000, sampling=\"log\")\n",
    "    lr = hp.Float(\"lr\",min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model = autoencoder(units,lr)\n",
    "    return model\n",
    "\n",
    "build_model( keras_tuner.HyperParameters())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 01m 42s]\n",
      "mean_squared_error: 0.0077662270826598006\n",
      "\n",
      "Best mean_squared_error So Far: 0.003190848510712385\n",
      "Total elapsed time: 00h 06m 35s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    hypermodel=build_model,\n",
    "    objective=\"mean_squared_error\",\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    seed = 333,\n",
    "    overwrite=True,\n",
    "    directory=\"/home/vmh/vmhdocs/Research/Inria/Anl/MetaGenAutoencoder/Code/autoenc001\",\n",
    "    project_name=\"tuner\",\n",
    ")\n",
    "\n",
    "\n",
    "tuner.search_space_summary()\n",
    "tb = kr.callbacks.TensorBoard(log_dir=\"./tuner_tb\", write_images=True,update_freq=\"epoch\")\n",
    "tuner.search(train_data, train_data, epochs=20,callbacks=[tb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 9024)]            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1180)              10649500  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1180)             4720      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 590)               696790    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 590)              2360      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 1773      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 3)                12        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 590)               2360      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 590)              2360      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1180)              697380    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 1180)             4720      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9024)              10657344  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,719,319\n",
      "Trainable params: 22,712,233\n",
      "Non-trainable params: 7,086\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get best model.\n",
    "best_model = tuner.get_best_models(num_models=1)\n",
    "best_model = best_model[0]\n",
    "\n",
    "# Build the model.\n",
    "best_model.build(input_shape=(inputlen,))\n",
    "best_model.summary()\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(1)\n",
    "best_hps = best_hps[0]\n",
    "# Build the model with the best hp.\n",
    "autoencoder = build_model(best_hps)\n",
    "autoencoder.save('./autoencoder_metagendata.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
